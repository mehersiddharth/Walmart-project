{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RL91aVGqDolo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from statsmodels.graphics.tsaplots import plot_acf,plot_pacf\n",
        "!pip install pmdarima\n",
        "from pmdarima import auto_arima\n",
        "from sklearn.model_selection import train_test_split\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from sklearn.metrics import *"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4VaMj4g7zLsp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/MyDrive/Colab Notebooks/Walmart.csv'\n",
        "data = pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "DusEw95Ezq4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Data Exploration**"
      ],
      "metadata": {
        "id": "eNx__iCaRr1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "ibkloOkiFlo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.dtypes"
      ],
      "metadata": {
        "id": "8oRF_Wq57t0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "id": "xRqzpJrbFteO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "ZtTJQgROFzbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.describe()"
      ],
      "metadata": {
        "id": "srq4Iq0ZF1Jc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking NULL values\n",
        "data.isnull().sum()"
      ],
      "metadata": {
        "id": "FPLFHBGsGBe9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking for duplicate values\n",
        "data.duplicated().sum()"
      ],
      "metadata": {
        "id": "IoutgdKZDyIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking for unique values in each column\n",
        "data.nunique().sort_values()"
      ],
      "metadata": {
        "id": "RsjQgy0aJtrg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.corr()"
      ],
      "metadata": {
        "id": "eiZ60h4jGJJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Data Transformation**"
      ],
      "metadata": {
        "id": "2Ht2P8ofSHrz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Conversion of 'Date' column: The 'Date' column  from a string format to a datetime format using the pd.to_datetime() function.\n",
        "# Creating New column for week,day,month,year\n",
        "# Sorting by 'Date': The datasets is sorted in ascending order based on the 'Date' column to ensure that the data is arranged chronologically."
      ],
      "metadata": {
        "id": "pvU9NJgmSrOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting Data Colummn\n",
        "data.Date=pd.to_datetime(data['Date'])\n",
        "\n",
        "#Creating New Columns\n",
        "data['week'] = data['Date'].dt.week\n",
        "data['day'] = data['Date'].dt.day\n",
        "data['month'] = data['Date'].dt.month\n",
        "data['year'] = data['Date'].dt.year\n",
        "data.head()\n",
        "\n",
        "#Sorting the Column in ascending order based on date column\n",
        "#data = data.sort_values('Date')\n",
        "\n",
        "data.head()"
      ],
      "metadata": {
        "id": "EDlYRRpdI16q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.tail()"
      ],
      "metadata": {
        "id": "CsQJICp4ZW1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(data.corr(),annot = True,fmt='.2f',cmap='Reds')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "c-6w_pFqHBKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Observations\n",
        "# 1. Based solely on corelation, we can infer that their is a positive corelation between Fuel Price and year\n",
        "# 2. Temperature,Fuel price, CPI and Unemployment are very weakly coorelated with the weekly sales"
      ],
      "metadata": {
        "id": "GbiCgiGvLYHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# distribution of Weekly_Sales\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(data=data, x='Weekly_Sales', kde=True)\n",
        "plt.title('Distribution of Weekly Sales')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4FKp3jgwQPdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**EDA**"
      ],
      "metadata": {
        "id": "5ljft7v-Rew-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Average Weekly Sales Store wise\n",
        "plt.figure(figsize=(15,7))\n",
        "sns.barplot(x='Store',y='Weekly_Sales',data=data,estimator='mean')\n",
        "plt.grid()\n",
        "plt.title('Average Weekly Sales per Store', fontsize=12)\n",
        "plt.ylabel('Sales')\n",
        "plt.xlabel('Store')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yQ7OOEOeLkGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Average weekly sales of 80% of stores is below 1500000"
      ],
      "metadata": {
        "id": "FGXquD_C5i4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Average Monthly Sales\n",
        "plt.figure(figsize=(12,5))\n",
        "sns.barplot(x='month',y='Weekly_Sales',data=data)\n",
        "plt.ylabel('Sales',fontsize=14)\n",
        "plt.xlabel('Months',fontsize=14)\n",
        "plt.title('Average Monthly Sales',fontsize=16)\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SqTnlCRMQiGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "sns.barplot(x='month', y='Weekly_Sales', hue='year', data=data)\n",
        "plt.ylabel('Sales', fontsize=14)\n",
        "plt.xlabel('Months', fontsize=14)\n",
        "plt.title('Average Monthly Sales by Year', fontsize=16)\n",
        "plt.grid()\n",
        "plt.legend(title='Year', title_fontsize='12', fontsize='12')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hohHSC6ZXt9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Month of January witnessed the lowest sales\n",
        "#From Feburary till October the weekly sales nearly remains constant\n",
        "#November and December showed the highest sales every year"
      ],
      "metadata": {
        "id": "hmNdYspL_q51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Average weekly salves VS year\n",
        "\n",
        "#filters the data for each year and calculates the mean of the 'Weekly_Sales' column for each week\n",
        "weekly_sales_2010 = data[data.year==2010].groupby('week')['Weekly_Sales'].mean()\n",
        "weekly_sales_2011 = data[data.year==2011].groupby('week')['Weekly_Sales'].mean()\n",
        "weekly_sales_2012 = data[data.year==2012].groupby('week')['Weekly_Sales'].mean()\n",
        "\n",
        "plt.figure(figsize=(15,8))\n",
        "plt.plot(weekly_sales_2010.index, weekly_sales_2010.values)\n",
        "plt.plot(weekly_sales_2011.index, weekly_sales_2011.values)\n",
        "plt.plot(weekly_sales_2012.index, weekly_sales_2012.values)\n",
        "\n",
        "plt.xticks(np.arange(1, 53, step=1), fontsize=10)\n",
        "plt.yticks( fontsize=10)\n",
        "plt.xlabel('Week of Year', fontsize=10)\n",
        "plt.ylabel('Sales', fontsize=10)\n",
        "\n",
        "plt.title(\"Average Weekly Sales - Per Year\", fontsize=24)\n",
        "plt.legend(['2010', '2011', '2012'], fontsize=20);\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kLhNn9EoAJvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Line plot of weekly sales over time\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.lineplot(data=data, x='Date', y='Weekly_Sales')\n",
        "plt.title('Weekly Sales Over Time')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Weekly Sales')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_Ij9cCpP7geD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# There's a clear pattern about the sales across the years, by the end of year the sales rise up by a huge margin."
      ],
      "metadata": {
        "id": "Ylsdsd5G5Ers"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "holiday_counts = data.Holiday_Flag.value_counts()"
      ],
      "metadata": {
        "id": "3s2qwcEYEog_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "holiday_sales = data.groupby('Holiday_Flag')['Weekly_Sales'].mean()"
      ],
      "metadata": {
        "id": "i4SFaF0sFuDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Plot 1 - Holiday Flag Counts\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.barplot(x=holiday_counts.index, y=holiday_counts.values)\n",
        "plt.ylabel('Count')\n",
        "plt.xlabel('Holiday Flag')\n",
        "plt.title('Holiday Flag Counts')\n",
        "\n",
        "# Plot 2 - Holiday vs non-Holiday Sales\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.barplot(x=holiday_sales.index, y=holiday_sales.values)\n",
        "plt.ylabel('Sales')\n",
        "plt.xlabel('Holiday Flag')\n",
        "plt.title('Holiday vs non-Holiday Sales')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xAoYI71ZJlEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Despite being the less percentage of holiday weeks the sales in the holidays week are higher than in the non-holiday weeks"
      ],
      "metadata": {
        "id": "RBLSd2bvJs6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Relationship between Temperature and sales\n",
        "plt.figure(figsize=(30, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.scatterplot(x=data.Temperature, y=data.Weekly_Sales)\n",
        "\n",
        "plt.xlabel('Temperature')\n",
        "plt.ylabel('Sales')\n",
        "plt.title('Temperature vs Sales')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.pointplot(x=\"Date\", y=\"Temperature\", data=data, color = 'red',linestyles='solid',errorbar=None)\n",
        "plt.xlabel('weeks')\n",
        "plt.ylabel('Temperature')\n",
        "plt.title('Temperature vs Time')\n",
        "plt.xticks([])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "L3uzmwp3KSBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# There seems to be no relatiobship between the temperature in the region and weekly sales of the stores.\n",
        "# At low and very high temperatures the sales seems to dip a bit but in general there doesn't exist a clear relationship\n",
        "# We can clearly shows Temperature is more of a seasonal and repeated in cycle"
      ],
      "metadata": {
        "id": "xvFilSazL94v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Relationship between FuelPrice and sales\n",
        "plt.figure(figsize=(20,5))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "sns.scatterplot(x=data.Fuel_Price, y=data.Weekly_Sales);\n",
        "\n",
        "plt.xlabel('Fuel_Price')\n",
        "plt.ylabel('Sales')\n",
        "plt.title('Fuel_Price vs Sales')\n",
        "\n",
        "#Fuel Price over the time\n",
        "plt.subplot(1, 3, 2)\n",
        "sns.pointplot(x=\"Date\", y=\"Fuel_Price\", data=data,color = 'orange',linestyles='solid',errorbar=None)\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Fuel_Price')\n",
        "plt.title('Fuel_Price over time')\n",
        "plt.xticks([])\n",
        "\n",
        "#Fuel price over the years\n",
        "plt.subplot(1, 3, 3)\n",
        "sns.barplot(x=data['year'],y=data['Fuel_Price'])\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Fuel_price')\n",
        "plt.title('Fuel_Price over years')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "4NxtRulLLQ3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Between fuel price and the sales there doesn't seem to exist any clear relationship\n",
        "# As the year increases fuel prices also increases"
      ],
      "metadata": {
        "id": "gTIoN7uTL241"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Relationship between CPI and sales\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.scatterplot(x=data.CPI, y=data.Weekly_Sales);\n",
        "\n",
        "plt.xlabel('CPI')\n",
        "plt.ylabel('Sales')\n",
        "plt.title('CPI vs Sales')\n",
        "\n",
        "# Change between CPI over time\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.pointplot(x=\"Date\", y=\"CPI\", data=data,color='lightgreen')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('CPI')\n",
        "plt.title('CPI over Time')\n",
        "plt.xticks([])\n",
        "\n",
        "\n",
        "plt.subplots_adjust(wspace=0.9)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4I42u1kzMCh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# There are 3 clear clusters but there doesn't exist any clear correlation between CPI and weekly sales"
      ],
      "metadata": {
        "id": "Q-GfWK1GMPYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Relationship between Unemployment and sales\n",
        "\n",
        "plt.figure(figsize=(15,5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.scatterplot(x=data.Unemployment, y=data.Weekly_Sales);\n",
        "\n",
        "plt.xlabel('Unemployment')\n",
        "plt.ylabel('Sales')\n",
        "plt.title('Unemployment vs Sales')\n",
        "\n",
        "# Change in Unemployment over time\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.pointplot(x=\"Date\", y=\"Unemployment\", data=data, color='khaki')\n",
        "plt.xlabel('Time Period')\n",
        "plt.ylabel('Unemployment')\n",
        "plt.title('Unemployment over Time')\n",
        "plt.xticks([])\n",
        "\n",
        "plt.subplots_adjust(wspace=0.9)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gmD75AkmMRbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# In relation to unemployment, it can be seen that the lower the Unemployment, higher the sales\n",
        "# Unemployment has decresed over time"
      ],
      "metadata": {
        "id": "90UrIOJsMrtk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Model**"
      ],
      "metadata": {
        "id": "P-rqclsfV1hD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "Uyci0B5yUuS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Extracting required data\n",
        "data1 = data[['Store', 'Date','Weekly_Sales']]\n",
        "data1.head()"
      ],
      "metadata": {
        "id": "psZw2e3WUuVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#preparing data for time series model\n",
        "#This extract the data for the given store number and prepares the dataset for time series model\n",
        "\n",
        "def select_store(data, store_number):\n",
        "    # Extract data for the specified store number\n",
        "    data_store = data[data['Store'] == store_number].drop('Store', axis=1)\n",
        "\n",
        "    # Set the 'Date' column as the index\n",
        "    data_store.index = pd.to_datetime(data_store['Date'])\n",
        "    del data_store['Date']\n",
        "\n",
        "    # Sort the DataFrame based on the index (date) in ascending order\n",
        "    data_store = data_store.sort_index(ascending=True)\n",
        "\n",
        "    return data_store\n",
        "\n",
        "\n",
        "\n",
        "# Call the function with the store number\n",
        "#store_number = 1\n",
        "#data_store = select_store(data1, store_number)\n",
        "\n",
        "# Display the processed data for Store 1\n",
        "#data_store\n"
      ],
      "metadata": {
        "id": "7N7ljkDzUuXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Store 1"
      ],
      "metadata": {
        "id": "DXCq0roNxK3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For Store 1\n",
        "store_number = 1\n",
        "data_store_1 = select_store(data1, store_number)\n"
      ],
      "metadata": {
        "id": "YnhZajAstLUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "\n",
        "decomposition = seasonal_decompose(data_store_1.Weekly_Sales, period=52)\n",
        "fig = plt.figure()\n",
        "fig = decomposition.plot()\n",
        "fig.set_size_inches(12, 10)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sPIEMsSPOqcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to calculate and plot rolling statistics\n",
        "def plot_rolling_stats(data, window_size):\n",
        "\n",
        "    # Sort the DataFrame based on the index (date) in ascending order\n",
        "    data = data.sort_index(ascending=True)\n",
        "\n",
        "    # Calculate rolling statistics (mean and standard deviation)\n",
        "    data['Rolling_Mean'] = data['Weekly_Sales'].rolling(window=window_size).mean()\n",
        "    data['Rolling_Std'] = data['Weekly_Sales'].rolling(window=window_size).std()\n",
        "\n",
        "    # Plot 'Weekly_Sales', rolling mean, and rolling standard deviation\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(data.index, data['Weekly_Sales'], label='Weekly Sales')\n",
        "    plt.plot(data.index, data['Rolling_Mean'], label='Rolling Mean', linestyle='--')\n",
        "    plt.plot(data.index, data['Rolling_Std'], label='Rolling Std', linestyle='-.')\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Weekly Sales')\n",
        "    plt.title('Weekly Sales with Rolling Mean and Rolling Std')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "-eDOPsW05KMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_rolling_stats(data_store_1, 4)"
      ],
      "metadata": {
        "id": "bf3iDUSgAlRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to check Checking the Stationarity of data\n",
        "#ADF test\n",
        "def adf_test(dataset):\n",
        "     dftest = adfuller(dataset, autolag = 'AIC')\n",
        "     print(\"1. ADF : \",dftest[0])\n",
        "     print(\"2. P-Value : \", dftest[1])\n",
        "     print(\"3. Num Of Lags : \", dftest[2])\n",
        "     print(\"4. Num Of Observations Used For ADF Regression:\",      dftest[3])\n",
        "     print(\"5. Critical Values :\")\n",
        "     for key, val in dftest[4].items():\n",
        "         print(\"\\t\",key, \": \", val)\n",
        "     if dftest[1] <= 0.05:\n",
        "      print(\"strong evidence against the null hypothesis, reject the null hypothesis. Data has no unit root and is stationary\")\n",
        "     else:\n",
        "      print(\"weak evidence against null hypothesis, time series has a unit root, indicating it is non-stationary \")\n",
        "\n",
        "\n",
        "#If p<0.05 ; Data is stationary\n",
        "#if p>0.05; Data is not stationary"
      ],
      "metadata": {
        "id": "wV54GZ8P8M4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adf_test(data_store_1['Weekly_Sales'])"
      ],
      "metadata": {
        "id": "GwTNUQzW8Oyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ACF & PACF (to find p,d,q)\n",
        "#from statsmodels.graphics.tsaplots import plot_acf,plot_pacf\n",
        "\n",
        "# Plot ACF\n",
        "plt.figure(figsize=(10, 5))\n",
        "plot_acf(data_store_1)\n",
        "plt.title('Autocorrelation Function (ACF)')\n",
        "plt.xlabel('Lags')\n",
        "plt.ylabel('Autocorrelation')\n",
        "plt.show()\n",
        "\n",
        "# Plot PACF\n",
        "plt.figure(figsize=(10, 5))\n",
        "plot_pacf(data_store_1)\n",
        "plt.title('Partial Autocorrelation Function (PACF)')\n",
        "plt.xlabel('Lags')\n",
        "plt.ylabel('Partial Autocorrelation')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oKYM58UHKguQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we can use this module to get the optimumn value for p,d,q\n",
        "\n",
        "#from pmdarima import auto_arima\n",
        "\n",
        "order1 = auto_arima(data_store_1['Weekly_Sales'], trace=True)\n",
        "order1.summary()"
      ],
      "metadata": {
        "id": "91zkwC-d9Y7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from the output we can see that the optimum value for (p,d,q) is (0,1,2)"
      ],
      "metadata": {
        "id": "NzjKJBhxy350"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the time series into train and test sets\n",
        "\n",
        "#from sklearn.model_selection import train_test_split\n",
        "train1,test1 = train_test_split(data_store_1,test_size = 0.10,shuffle=False)\n",
        "\n",
        "# Plotting both graphs in one figure with different colors\n",
        "plt.figure(figsize=(20, 6))\n",
        "plt.plot(train1.index, train1, label='train', color='blue')\n",
        "plt.plot(test1.index, test1, label='test', color='red')\n",
        "\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Value')\n",
        "plt.title('Train and Test Time Series')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MNb1NIXvF315"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ARIMA Model\n"
      ],
      "metadata": {
        "id": "xWQzAbu-zKwD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from statsmodels.tsa.arima.model import ARIMA\n",
        "\n",
        "model_Store1_1=ARIMA(train1['Weekly_Sales'],order=(0,1,2))\n",
        "model_Store1_1_fit=model_Store1_1.fit()\n",
        "#model_Store1_1_fit.summary()"
      ],
      "metadata": {
        "id": "l99aJnZlIDLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_Store1_1 = model_Store1_1_fit.predict(start=len(train1),end=(len(data_store_1)-1))"
      ],
      "metadata": {
        "id": "lpe5R5XoSXXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test1_index = test1.index\n",
        "prediction_Store1_1.index = test1_index"
      ],
      "metadata": {
        "id": "u0lwSUN1VkQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20, 6))\n",
        "plt.plot(train1.index, train1, label='train', color='blue')\n",
        "plt.plot(test1.index, test1, label='test', color='orange')\n",
        "plt.plot(prediction_Store1_1.index, prediction_Store1_1, label='test', color='red')"
      ],
      "metadata": {
        "id": "e7mTzyd4YA7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_Store1_1\n",
        "prediction_df = prediction_Store1_1.to_frame(name='Predicted_Weekly_Sales')\n",
        "prediction_df['Predicted_Weekly_Sales'] = prediction_df['Predicted_Weekly_Sales'].astype(int)\n",
        "prediction_df"
      ],
      "metadata": {
        "id": "q4KwzMcwkUWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mae = mean_absolute_error(test1['Weekly_Sales'], prediction_df['Predicted_Weekly_Sales'])\n",
        "print(\"ARIMA Model - MAE:\",mae)\n",
        "mse = mean_squared_error(test1['Weekly_Sales'], prediction_df['Predicted_Weekly_Sales'])\n",
        "print(\"ARIMA Model - MSE:\", mse)\n",
        "rmse = rmse = np.sqrt(mse)\n",
        "print(\"ARIMA Model - RMSE:\", rmse)"
      ],
      "metadata": {
        "id": "xNxm9t4ul08G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SARIMA Model"
      ],
      "metadata": {
        "id": "A1ec9Y8M0pw8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "model_Store1_2 = SARIMAX(train1['Weekly_Sales'],order=(0,1,2),seasonal_order=(0,1,2,52))\n",
        "model_Store1_2_fit=model_Store1_2.fit()\n",
        "#model_Store1_2_fit.summary()"
      ],
      "metadata": {
        "id": "xX1WE2smYRbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_Store1_2 = model_Store1_2_fit.predict(start=len(train1),end=(len(data_store_1)-1))"
      ],
      "metadata": {
        "id": "P4hJSQ5Maj87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test1_index = test1.index\n",
        "prediction_Store1_2.index = test1_index"
      ],
      "metadata": {
        "id": "p-gdXDvaagmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20, 6))\n",
        "plt.plot(train1.index, train1, label='train', color='blue')\n",
        "plt.plot(test1.index, test1, label='test', color='orange')\n",
        "plt.plot(prediction_Store1_2.index, prediction_Store1_2, label='test', color='red')\n"
      ],
      "metadata": {
        "id": "wKAYsrj2bCWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Future Prediction"
      ],
      "metadata": {
        "id": "k_I9MG7vX3Np"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Forcasting values for next 12 weeks\n",
        "\n",
        "# Create the SARIMA model and fit it to the entire dataset.\n",
        "model1_f = SARIMAX(data_store_1['Weekly_Sales'], order=(0, 1, 2), seasonal_order=(0, 1, 2, 52))\n",
        "model1_f_fit = model1_f.fit()\n",
        "\n",
        "# Predict data for the next 12 weeks.\n",
        "predictionf_1 = model1_f_fit.predict(start=len(data_store_1), end=len(data_store_1) + 11)\n",
        "\n",
        "# Create a date range for the next 12 weeks (assuming 'data_store_1' has a DatetimeIndex).\n",
        "next_12_weeks = pd.date_range(start=data_store_1.index[-1], periods=12, freq='W')\n",
        "\n",
        "# Assign the index to the predictions for plotting.\n",
        "predictionf_1.index = next_12_weeks\n",
        "\n",
        "# Convert the prediction Series to a DataFrame.\n",
        "predictionf_1_df = predictionf_1.to_frame(name='Predicted_Weekly_Sales')\n",
        "predictionf_1_df['Predicted_Weekly_Sales'] = predictionf_1_df['Predicted_Weekly_Sales'].astype(int)\n",
        "\n",
        "# Merge the predicted DataFrame with the original data_store_1 DataFrame.\n",
        "data_with_predictions_1 = pd.concat([data_store_1, predictionf_1_df])\n",
        "\n",
        "# Plot the graph.\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(data_with_predictions_1.index, data_with_predictions_1['Weekly_Sales'], label='Actual')\n",
        "plt.plot(data_with_predictions_1.index, data_with_predictions_1['Predicted_Weekly_Sales'], label='Predicted', color='red')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Weekly Sales')\n",
        "plt.title('Weekly Sales Prediction for the Next 12 Weeks of Store 1')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "L8qWv4waiaiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to create 1) ARIMA Model\n",
        "#                   2) SARIMA Model\n",
        "#                   3) Future Forecast\n",
        "#and plot their graphs\n",
        "\n",
        "def arima_forecast(train, test, order):\n",
        "\n",
        "  with warnings.catch_warnings():\n",
        "    warnings.simplefilter(\"ignore\")\n",
        "\n",
        "    # Fit the ARIMA model\n",
        "    model = ARIMA(train['Weekly_Sales'], order=order)\n",
        "    model_fit = model.fit()\n",
        "\n",
        "    # Make predictions\n",
        "    predictions = model_fit.predict(start=len(train), end=(len(train) + len(test) - 1))\n",
        "\n",
        "    # Set prediction index to match test index\n",
        "    predictions.index = test.index\n",
        "\n",
        "    # Plot the results\n",
        "    plt.figure(figsize=(20, 6))\n",
        "    plt.plot(train.index, train['Weekly_Sales'], label='train', color='blue')\n",
        "    plt.plot(test.index, test['Weekly_Sales'], label='test', color='orange')\n",
        "    plt.plot(predictions.index, predictions, label='predictions', color='red')\n",
        "    plt.title('Weekly Sales Prediction using ARIMA Model')\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Weekly Sales')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    return predictions\n",
        "\n",
        "def sarima_forecast(train, test, seasonal_order,order):\n",
        "  with warnings.catch_warnings():\n",
        "    warnings.simplefilter(\"ignore\")\n",
        "    # Fit the SARIMA model\n",
        "    model = SARIMAX(train['Weekly_Sales'], order=order, seasonal_order=seasonal_order)\n",
        "    model_fit = model.fit()\n",
        "\n",
        "    # Make predictions\n",
        "    predictions = model_fit.predict(start=len(train), end=(len(train) + len(test) - 1))\n",
        "\n",
        "    # Set prediction index to match test index\n",
        "    predictions.index = test.index\n",
        "\n",
        "    # Plot the results\n",
        "    plt.figure(figsize=(20, 6))\n",
        "    plt.plot(train.index, train['Weekly_Sales'], label='train', color='blue')\n",
        "    plt.plot(test.index, test['Weekly_Sales'], label='test', color='orange')\n",
        "    plt.plot(predictions.index, predictions, label='predictions', color='red')\n",
        "    plt.title('Weekly Sales Prediction using SARIMA Model')\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Weekly Sales')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    return predictions\n",
        "\n",
        "def future_forecast(data, order, seasonal_order):\n",
        "  with warnings.catch_warnings():\n",
        "    warnings.simplefilter(\"ignore\")\n",
        "    # Create the SARIMA model and fit it to the entire dataset.\n",
        "    model = SARIMAX(data['Weekly_Sales'], order=order, seasonal_order=seasonal_order)\n",
        "    model_fit = model.fit()\n",
        "\n",
        "    # Predict data for the next 12 weeks.\n",
        "    prediction = model_fit.predict(start=len(data), end=len(data) + 11)\n",
        "\n",
        "    # Create a date range for the next 12 weeks (assuming 'data' has a DatetimeIndex).\n",
        "    next_12_weeks = pd.date_range(start=data.index[-1], periods=12, freq='W')\n",
        "\n",
        "    # Assign the index to the predictions for plotting.\n",
        "    prediction.index = next_12_weeks\n",
        "\n",
        "    # Convert the prediction Series to a DataFrame.\n",
        "    prediction_df = prediction.to_frame(name='Predicted_Weekly_Sales')\n",
        "    prediction_df['Predicted_Weekly_Sales'] = prediction_df['Predicted_Weekly_Sales'].astype(int)\n",
        "\n",
        "    # Merge the predicted DataFrame with the original data DataFrame.\n",
        "    data_with_predictions = pd.concat([data, prediction_df])\n",
        "\n",
        "    # Plot the graph.\n",
        "    plt.figure(figsize=(20, 6))\n",
        "    plt.plot(data_with_predictions.index, data_with_predictions['Weekly_Sales'], label='Actual',color='blue')\n",
        "    plt.plot(data_with_predictions.index, data_with_predictions['Predicted_Weekly_Sales'], label='Predicted', color='red')\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Weekly Sales')\n",
        "    plt.title('Weekly Sales Prediction for the Next 12 Weeks')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    return data_with_predictions\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nGvOJfrnKsNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For Store 25\n",
        "store_number = 25\n",
        "data_store_25 = select_store(data1, store_number)\n",
        "train25,test25 = train_test_split(data_store_25,test_size = 0.10,shuffle=False)"
      ],
      "metadata": {
        "id": "qoRbET77Od7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = train25\n",
        "test = test25\n",
        "order = (0, 1, 2)\n",
        "seasonal_order = (0,1,2,52)\n",
        "data = data_store_25\n",
        "arima_forecast(train, test, order)\n",
        "sarima_forecast(train, test, seasonal_order,order)\n",
        "future_forecast(data, order, seasonal_order)"
      ],
      "metadata": {
        "id": "wZo_Se3WKwVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For Store 35\n",
        "store_number = 35\n",
        "data_store_35 = select_store(data1, store_number)\n",
        "train35,test35 = train_test_split(data_store_35,test_size = 0.10,shuffle=False)"
      ],
      "metadata": {
        "id": "FQejXB5kRWQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = train35\n",
        "test = test35\n",
        "order = (0, 1, 2)\n",
        "seasonal_order = (0,1,2,52)\n",
        "data = data_store_35\n",
        "arima_forecast(train, test, order)\n",
        "sarima_forecast(train, test, seasonal_order,order)\n",
        "future_forecast(data, order, seasonal_order)"
      ],
      "metadata": {
        "id": "JLp5Sh-LRX8W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}